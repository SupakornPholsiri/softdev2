import unittest
from unittest.mock import patch,mock_open
from Tokenize import Tokenize

#Test Tokenize
class Test(unittest.TestCase):
    
    def test_Tokenize_1stcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© 1
        Tokenizer = Tokenize()
        test1 = "crying cry cries"
        self.assertEqual(Tokenizer.tokenize(test1),["cry","cry","cry"])
    def test_Tokenize_2ndcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏ì‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© 2
        Tokenizer = Tokenize()
        test1 = "Crying crying cried"
        self.assertEqual(Tokenizer.tokenize(test1),["Crying","cry","cried"])
    def test_Tokenize_3rdcase(self):
        #‡πÄ‡∏Ñ‡∏™ Emoji
        Tokenizer = Tokenize()
        test1 = "It is really üòôüëå"
        self.assertEqual(Tokenizer.tokenize(test1),["It","is","really"])
    def test_Tokenize_4thcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        Tokenizer = Tokenize()
        test1 = "Oh Baby Baby ‡∏≠‡∏π‡πâ ‡πÇ‡∏ß‡πâ‡∏ß"
        self.assertEqual(Tokenizer.tokenize(test1),["Oh","Baby","Baby","‡∏≠‡∏π‡πâ","‡πÇ‡∏ß‡πâ‡∏ß"])
    def test_Tokenize_5thcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏£‡∏ß‡∏° Emoji ‡πÑ‡∏ó‡∏¢ ‡πÄ‡πÄ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        Tokenizer = Tokenize()
        test1 = "Oh Baby Baby ‡∏≠‡∏π‡πâ ‡πÇ‡∏ß‡πâ‡∏ß ‡πÇ‡∏à‡πâ‡∏ß ‡πÇ‡∏à‡πâ‡∏ß ‡πÄ‡∏≠‡∏¥‡πâ‡∏ö üôå üôå üôå üôå"
        self.assertEqual(Tokenizer.tokenize(test1),["Oh","Baby","Baby","‡∏≠‡∏π‡πâ","‡πÇ‡∏ß‡πâ‡∏ß","‡πÇ‡∏à‡πâ‡∏ß","‡πÇ‡∏à‡πâ‡∏ß","‡πÄ‡∏≠‡∏¥‡πâ‡∏ö"])
    def test_Tokenize_6thcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©
        Tokenizer = Tokenize()
        test1 = "I‚ñ∂you"
        self.assertEqual(Tokenizer.tokenize(test1),["I","you"])
    def test_Tokenize_7thcase(self):
        #‡πÄ‡∏Ñ‡∏™ Punctuation
        Tokenizer = Tokenize()
        test1 = "Banana-cupcake"
        self.assertEqual(Tokenizer.tokenize(test1),["Banana","cupcake"])
        
        
    def test_Tokenizefilter_1stcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        Tokenizer = Tokenize()
        test1 = ["It","s","really","nice"]
        self.assertEqual(Tokenizer.filter(test1),["It","really","nice"])
    def test_Tokenizefilter_2stcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        Tokenizer = Tokenize()
        test1 = ["‡∏Å‡∏π","‡∏ö","‡πÄ‡∏õ‡πá‡∏ô","‡∏´‡∏¢‡∏±‡∏á"]
        self.assertEqual(Tokenizer.filter(test1),["‡∏Å‡∏π","‡πÄ‡∏õ‡πá‡∏ô","‡∏´‡∏¢‡∏±‡∏á"])
    def test_Tokenizefilter_3stcase(self):
        #‡πÄ‡∏Ñ‡∏™‡∏£‡∏ß‡∏°‡πÑ‡∏ó‡∏¢ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        Tokenizer = Tokenize()
        test1 = ["‡∏Å‡∏π","‡∏ö","‡πÄ‡∏õ‡πá‡∏ô","‡∏´‡∏¢‡∏±‡∏á","I","a","Okay","‡∏ô‡∏∞","‡∏¢‡∏π","‡πÇ‡∏ô‡∏ß"]
        self.assertEqual(Tokenizer.filter(test1),["‡∏Å‡∏π","‡πÄ‡∏õ‡πá‡∏ô","‡∏´‡∏¢‡∏±‡∏á","Okay","‡∏ô‡∏∞","‡∏¢‡∏π","‡πÇ‡∏ô‡∏ß"])
        
        
        
if __name__ == '__main__':
    unittest.main()
        